import { ImageResponse } from "@vercel/og";
import { toString } from "hast-util-to-string";
import { createOCRManager } from "unocr";
import tesseractDriver from "../../packages/unocr/src/drivers/tesseract";

/**
 * Generate test image using Vercel OG and then test OCR recognition
 */
async function testOCRWithOGImage() {
  console.log("ğŸ¦œ Testing unocr with @vercel/og generated image...\n");

  // Test text to generate and recognize
  const testText = "Hello";
  console.log(`ğŸ“ Original text: "${testText}"`);

  try {
    // Generate image using Vercel OG
    console.log("\nğŸ¨ Generating image with @vercel/og...");
    const imageResponse = new ImageResponse(
      {
        type: "div",
        props: {
          style: {
            background: "white",
            width: "100%",
            height: "100%",
            display: "flex",
            alignItems: "center",
            justifyContent: "center",
            fontFamily: "Arial",
            fontSize: "48px",
            color: "black",
            padding: "20px",
            textAlign: "center",
          },
          children: testText,
        },
      },
      {
        width: 400,
        height: 200,
      },
    );

    // Convert to PNG Buffer
    const arrayBuffer = await imageResponse.arrayBuffer();
    const imageBuffer = Buffer.from(arrayBuffer);

    // Save image to file for debugging
    console.log(`âœ… Image generated and saved (${imageBuffer.length} bytes)`);

    // Create OCR manager using factory function
    console.log("\nğŸš€ Creating OCR manager...");
    const ocr = createOCRManager({
      driver: tesseractDriver({
        langs: "eng",
        logger: (m) => {
          if (m.status === "recognizing text") {
            process.stdout.write(
              `\râ³ OCR Progress: ${Math.round((m.progress || 0) * 100)}%`,
            );
          }
        },
      }),
    });

    // Perform OCR recognition
    console.log("\nğŸ” Starting OCR recognition...");
    const startTime = Date.now();
    const result = await ocr.recognize(imageBuffer);
    const processingTime = Date.now() - startTime;

    // Extract text from hast result using hast-util-to-string
    const recognizedText = toString(result).trim();
    console.log(`\nâœ… OCR completed in ${processingTime}ms`);
    console.log(`ğŸ“– Recognized text: "${recognizedText}"`);

    // Compare results
    console.log("\nğŸ“Š Comparison Results:");
    console.log(`Original:   "${testText}"`);
    console.log(`Recognized: "${recognizedText}"`);
    console.log(
      `Match:      ${testText === recognizedText ? "âœ… YES" : "âŒ NO"}`,
    );

    // Clean up
    await ocr.dispose();
    console.log("\nğŸ§¹ OCR manager disposed successfully");
  } catch (error) {
    console.error(
      "\nâŒ Test failed:",
      error instanceof Error ? error.message : error,
    );
  }
}

/**
 * Test batch processing with multiple generated images
 */
async function testBatchProcessing() {
  console.log("\n" + "=".repeat(50));
  console.log("ğŸ”„ Testing batch OCR processing...\n");

  const testTexts = ["Hello", "World", "Test", "123"];

  try {
    // Generate multiple images
    console.log("ğŸ¨ Generating multiple images...");
    const images: Buffer[] = [];

    for (const text of testTexts) {
      const imageResponse = new ImageResponse(
        {
          type: "div",
          props: {
            style: {
              background: "white",
              width: "100%",
              height: "100%",
              display: "flex",
              alignItems: "center",
              justifyContent: "center",
              fontFamily: "Arial",
              fontSize: "36px",
              color: "black",
              padding: "20px",
              textAlign: "center",
            },
            children: text,
          },
        },
        {
          width: 300,
          height: 100,
        },
      );

      const arrayBuffer = await imageResponse.arrayBuffer();
      const buffer = Buffer.from(arrayBuffer);
      images.push(buffer);
    }

    console.log(`âœ… Generated ${images.length} images`);

    // Create OCR manager and test batch processing
    const ocr = createOCRManager({
      driver: tesseractDriver({
        langs: "eng",
      }),
    });
    console.log("\nğŸ” Starting batch OCR recognition...");

    const startTime = Date.now();
    const results = await ocr.recognizes(images, { parallel: 2 });
    const processingTime = Date.now() - startTime;

    console.log(`\nâœ… Batch OCR completed in ${processingTime}ms`);

    // Extract and display results
    console.log("\nğŸ“Š Batch Results:");
    results.forEach((result, index) => {
      const text = toString(result).trim();
      console.log(
        `${index + 1}. "${testTexts[index]}" â†’ "${text}" (${testTexts[index] === text ? "âœ…" : "âŒ"})`,
      );
    });

    await ocr.dispose();
  } catch (error) {
    console.error(
      "\nâŒ Batch test failed:",
      error instanceof Error ? error.message : error,
    );
  }
}

// Run tests
async function runTests() {
  await testOCRWithOGImage();
  await testBatchProcessing();

  console.log("\n" + "=".repeat(50));
  console.log("ğŸ‰ All tests completed!");
}

// Run tests
runTests().catch(console.error);
